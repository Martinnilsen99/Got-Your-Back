{"cells":[{"cell_type":"markdown","source":"### Pytorch Model\n\nLager en enkel modell med 2 lineære lag","metadata":{"cell_id":"00000-151bc8da-97bd-4e7d-961c-e3750b7c8724","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00001-69448d5c-2153-46c8-81b4-c589317f9b22","deepnote_cell_type":"code"},"source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass Model(nn.Module):\n    def __init__(self, input_shape=49, output_shape=9, lr=0.001):\n        super(Model, self).__init__()\n        self.input_shape = input_shape\n        self.output_shape = output_shape\n        self.lr = lr\n        self.net = torch.nn.Sequential(\n            torch.nn.Linear(input_shape, 25),\n            torch.nn.ReLU(),\n            torch.nn.Linear(25, output_shape),\n        )\n        self.opt = optim.SGD(self.net.parameters(), lr=lr, momentum=0.9)\n        #self.opt = optim.Adam(self.net.parameters(), lr=lr)\n        #self.opt = optim.RMSprop(self.net.parameters(), lr=lr)\n        self.criterion = nn.CrossEntropyLoss()\n\n    def forward(self, x):\n        return self.net(x)\n    \n    def accuracy(self, x, y):\n        return torch.mean(torch.eq(self.forward(x).argmax(1), y.argmax(1)).float())\n\n    \"\"\"\n    # Uses Cross Entropy\n    def loss(self, x, y):\n        return torch.nn.functional.binary_cross_entropy_with_logits(self.f(x), y)\n    \"\"\"\n    def loss(self, x, y):\n        return self.criterion(self.forward(x), y)\n","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training\n\nDenne er hentet ut fra [Pytorch egen nettside](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)","metadata":{"cell_id":"00002-99756569-aa7f-4225-aca9-5bc8fb0d3a46","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00003-de95bf18-8ed0-42c6-800a-babbfbc2491e","deepnote_cell_type":"code"},"source":"LR = 0.001\nEPOCH = 100\nAMOUNT_OF_SENSORS = 3\n\nmodel = Model(input_shape=(AMOUNT_OF_SENSORS*16)+1, output_shape=len(POSE_MAP), lr=LR)\n\n#Vi må dele opp i rader og skille ut en 7tensor med dataattributter og en tensor med labels\nfor epoch in range(2):  # loop over the dataset multiple times\n    running_loss = 0.0\n    for i, data in enumerate(x_train, 0):\n        # zero the parameter gradients\n        model.opt.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model.forward(inputs)\n        loss = model.criterion(outputs, labels)\n        loss.backward()\n        model.opt.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                    (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training')\n\nresults = []\nfor index, epoch in enumerate(range(EPOCH)):\n    model.opt.zero_grad()\n\n    # forward + backward + optimize\n    loss = model.loss(torch.tensor(x_train.values), torch.tensor(y_train.values))\n    loss.backward()\n    model.opt.step()\n\n    if (index+1) % 10 == 0:\n        print(f'epoch = {index+1}, loss = {model.loss(x_train, y_train).item()}, accuracy = {model.accuracy(x_test, y_test).item() * 100}%')\n        results.append([index+1, model.loss(x_train, y_train).item(),\n                        model.accuracy(x_test, y_test).item() * 100])\n\n    model.loss(x_train, y_train).backward()  # Compute loss gradients\n    model.opt.step()  # Perform optimization by adjusting W and b\n\nprint(tabulate.tabulate(results, headers=['epoch', 'loss', 'accuracy']))","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=59d486bc-e14d-4632-9064-12272fc72d11' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2-final"},"orig_nbformat":2,"kernelspec":{"name":"python38264bit6348f0fb647549c7908291a257a0f019","display_name":"Python 3.8.2 64-bit","language":"python"},"deepnote_notebook_id":"2bb18714-6887-4505-acc5-b1ddfd4260d5","deepnote":{},"deepnote_execution_queue":[]}}