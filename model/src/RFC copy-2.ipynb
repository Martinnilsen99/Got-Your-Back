{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Import",
   "metadata": {
    "tags": [],
    "cell_id": "00000-b2ea635c-10a4-4864-87ac-04c0d8e58890",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1912,
    "execution_start": 1620978218282,
    "source_hash": "ee38c6e2",
    "cell_id": "00001-5636d77f-1b18-4237-93c4-2c41341f6485",
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "import sys; sys.path.insert(0, '..')\nimport os\nimport time\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom tabulate import tabulate\nfrom utils.df_utils import df_wrapper\nfrom dataclasses import dataclass\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.utils import shuffle\nfrom utils.declarations import training_files, testing_files, POSE_MAP",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Define data",
   "metadata": {
    "tags": [],
    "cell_id": "00002-be0fb920-5bb4-4c4f-bb5a-f0872cd09dde",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1620978220194,
    "source_hash": "7339921f",
    "cell_id": "00003-d0a1f74f-a114-4332-910a-ab80f45e3e5e",
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "AMOUNT_OF_SENSORS = 3\nVALIDATION_TESTSET = \"004\"",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Datapreparation",
   "metadata": {
    "tags": [],
    "cell_id": "00004-a71046d0-0a9d-4d5a-ae8f-4476278c5800",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### Train",
   "metadata": {
    "tags": [],
    "cell_id": "00005-432fde07-372d-4857-9f20-a9aa087f1dc0",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 167245,
    "execution_start": 1620978220195,
    "is_code_hidden": false,
    "output_cleared": true,
    "source_hash": "1c99bc3",
    "cell_id": "00006-ecff3bdb-40f0-45b5-b10d-ab1b607c28c7",
    "deepnote_cell_type": "code"
   },
   "source": "x_train_arr = []\nfor key in training_files:\n    elem = df_wrapper(training_files[key].csv_file)\n    elem.concat_sensor_data(AMOUNT_OF_SENSORS)\n    elem.align_poses(training_files[key].annot_file, POSE_MAP)\n    x_train_arr.append(elem)\n\nx_train_arr = shuffle(x_train_arr)\nx_train = pd.concat([x.df.drop([' TimeStamp (s)', 'Pose'],axis=1) for x in x_train_arr])\ny_train = pd.concat([x.df['Pose'] for x in x_train_arr])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Test\n",
   "metadata": {
    "tags": [],
    "cell_id": "00007-27a3655e-7837-4de3-b68e-849d5315bf10",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8620,
    "execution_start": 1620978387483,
    "source_hash": "9134ee95",
    "tags": [],
    "cell_id": "00008-e3d4ba49-6073-4f50-bce0-900c2517c3bb",
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "x_test_dict = dict()\ny_test_dict = dict()\nfor key in testing_files:\n    elem = df_wrapper(testing_files[key].csv_file)\n    elem.concat_sensor_data(AMOUNT_OF_SENSORS)\n    elem.align_poses(testing_files[key].annot_file, POSE_MAP)\n    y_test = elem.df[\"Pose\"]\n    y_test.index = [i for i in range(len(y_test))]\n    x_test_dict[key] = elem.df\n    y_test_dict[key] = y_test\n\nx_test = x_test_dict[VALIDATION_TESTSET].drop([' TimeStamp (s)', 'Pose'], axis=1) \ny_test = y_test_dict[VALIDATION_TESTSET]\nx_test_dict.pop(VALIDATION_TESTSET)\ny_test_dict.pop(VALIDATION_TESTSET)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1620978396097,
    "execution_millis": 3,
    "cell_id": "00009-7383515f-ddb8-4c00-aecc-a1867ef71a63",
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Visualisation",
   "metadata": {
    "tags": [],
    "cell_id": "00010-c5e39c63-d03f-424b-b948-dbd9f19e9746",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 29863,
    "execution_start": 1620978396142,
    "output_cleared": true,
    "source_hash": "6e5d68f6",
    "cell_id": "00011-e3335f54-2212-4689-ae8c-4a0d988834d0",
    "deepnote_cell_type": "code"
   },
   "source": "cols = []\nheight=30\nwidth=(height/2)*len(x_train_arr)\nfig, axes = plt.subplots(4,  max(len(training_files), len(testing_files)), figsize=(width, height))\nfig.suptitle('Data visualisation')\n# Train\nfor i in range(len(x_train_arr)):\n    sns.lineplot(ax=axes[0, i], data=x_train_arr[i].df, x=\" TimeStamp (s)\", y='Pose')\n    sns.histplot(ax=axes[1, i], data=x_train_arr[i].df[\"Pose\"])\n    cols.append(f'Train {key}')    \nfor ax, col in zip(axes[0], cols):\n    ax.set_title(col)\n# Test\ncols=[]\nfor i, key in enumerate(x_test_dict):\n    sns.lineplot(ax=axes[2, i], data=x_test_dict[key], x=\" TimeStamp (s)\", y='Pose')\n    sns.histplot(ax=axes[3, i], data=y_test_dict[key])\n    cols.append(f'Test {key}')\nfor ax, col in zip(axes[2], cols):\n    ax.set_title(col)\nfig.tight_layout()\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Adjust dataframes",
   "metadata": {
    "tags": [],
    "cell_id": "00012-98e34a67-1e54-4cb1-9395-13dfc6452014",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1620978426036,
    "source_hash": "9fa56c82",
    "cell_id": "00013-96170178-bda5-4265-ac90-ce865b092808",
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "x_train_numpy = x_train.values\nx_test_numpy = x_test.values\ny_train_numpy = y_train.values\ny_test_numpy = y_test.values",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### GridSearch",
   "metadata": {
    "tags": [],
    "cell_id": "00014-88e3838b-2e53-4a0e-8b82-57b41359befb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## RFC            ",
   "metadata": {
    "tags": [],
    "cell_id": "00015-c3d994f5-f926-421e-9b13-b6d88ed4fb08",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Precision",
   "metadata": {
    "tags": [],
    "cell_id": "00016-b22f6541-3bd4-480e-8bbe-00533abf864e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1620978426038,
    "output_cleared": true,
    "source_hash": "89fb2e24",
    "tags": [],
    "cell_id": "00017-132056a1-495f-4c18-8d51-7c59c5b9b750",
    "deepnote_cell_type": "code"
   },
   "source": "# Evaluation methods\nimport math\nimport numpy\nfrom sklearn.model_selection import KFold,RepeatedStratifiedKFold, cross_val_score\n\ndef evaluate_model(model, X, y):\n\t# define the evaluation procedure\n\tcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n\t# evaluate the model and collect the results\n\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n\treturn scores\n\n\ndef evaluate_w_validation_set(model, x, y):\n    model.fit(x, y)\n    classifications = model.predict(x_test)\n    annotated_positions = y_test.to_numpy()\n    correct_classifications = (classifications == annotated_positions).sum()\n    accuracy = round(correct_classifications/len(classifications)*100,2)\n\n    return accuracy\n\n\ndef find_oob_err(max_features=None, max_samples=None, n_estimators=10):\n    rfc = RandomForestClassifier(n_estimators=i, max_features=max_features, oob_score=True, random_state=33, max_samples=max_samples)\n    rfc.fit(x_train, y_train)\n    print(\"rfc oob_score: \", rfc.oob_score_)\n    err = 1-rfc.oob_score_\n    \n    print(\"1-oob_score: \", err)\n    return err\n\n\ndef find_test_accuracy(model, x, y):\n    model.fit(x_train, y_train)\n    print(\"Classification accuracy:\")\n    classification_dict = dict()\n    accuracy_list = list()\n\n    for key in x_test_dict:\n        x_test = x_test_dict[key].drop([' TimeStamp (s)', 'Pose'], axis=1)\n        classifications = model.predict(x_test)\n        annotated_positions = y_test_dict[key].to_numpy()\n        correct_classifications = (classifications == annotated_positions).sum()\n        accuracy_list.append(round(correct_classifications/len(classifications)*100,2))\n        print(f\"{key}: {accuracy_list[-1]}%\")\n        classification_dict[key] = classifications\n\n    avg = round(sum(accuracy_list)/len(accuracy_list),2)\n    print(f\"Average accuracy: {avg}%\\nWith {estimators} estimators and\\nrandom_state={33}\")\n    return avg\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1049807,
    "execution_start": 1620978426039,
    "source_hash": "d2407773",
    "tags": [],
    "cell_id": "00018-47adc534-02d2-4abd-98eb-de79f45e36da",
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# Find best amount of features with cross_validation\ndef get_models_features(n_estimators=10):\n\tmodels = dict()\n\t# explore number of features\n\tfor i in range(1, math.ceil(((AMOUNT_OF_SENSORS*13)+1)/2)):\n\t\tmodels[str(i)] = RandomForestClassifier(max_features=i, n_estimators=n_estimators, random_state=33)\n\treturn models\n\n\nfeature_models = get_models_features()\nfeature_val_scores = []\nfor i in range(len(feature_models)):\n    feature_val_score = evaluate_w_validation_set(feature_models[str(i+1)], x_train, y_train)\n    feature_val_scores.append(feature_val_score)\nbest_feature_amount = feature_val_scores.index(max(feature_val_scores))+1\nprint(\"best_featue_amount: \", best_feature_amount)\n\nplt.plot([i for i in range(1,len(feature_val_scores)+1)], feature_val_scores)\nplt.xlabel(\"Amount of features\")\nplt.ylabel(\"Validation average score\")\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5b4afa3e",
    "tags": [],
    "execution_start": 1620979475846,
    "execution_millis": 196538,
    "cell_id": "00019-2cf27c02-f163-4664-b2c0-850a07452a8d",
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# Find best amount of samples for dataset\nimport numpy\ndef get_models_samples(n_estimators=10, max_features=None):\n    models = dict()\n    # explore ratios from 10% to 100% in 10% increment\n    for i in numpy.arange(0.1, 1.1, 0.1):\n        key = '%.1f' % i\n        # set max_samples=None to use 100%\n        if i == 1.0:\n            i = None\n        models[str(i)] = RandomForestClassifier(max_samples=i, random_state=33, n_estimators=n_estimators)\n        print(i)\n    return models\n\nsample_models = get_models_samples()\nsamples_val_scores = []\nfor samples, model in sample_models.items():\n    val_score = evaluate_w_validation_set(model, x_train, y_train)\n    samples_val_scores.append(val_score)\nbest_sample_amount = float(list(sample_models.keys())[samples_val_scores.index(max(samples_val_scores))])\nprint(\"best_sample_amount: \", best_sample_amount)\n \nplt.plot(list(sample_models.keys()), samples_val_scores)\nplt.xlabel(\"Percentage of all available samples\")\nplt.ylabel(\"Validation score\")\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2e31d2e9",
    "tags": [],
    "execution_start": 1621021753069,
    "execution_millis": 466,
    "cell_id": "00020-3fb07365-4dec-4b08-8af9-a68d7dc56b9c",
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# Find best rfc overall\n\"\"\"def get_models_estimators(max_features=None, max_samples=None):\n    models = dict()\n    for i in range(1, 162, 20):\n        models[str(i)] = RandomForestClassifier(max_features=max_features, max_samples=max_samples, n_estimators=i, random_state=33)\n    return models\n\nestimator_models = get_models_estimators(max_features=best_feature_amount, max_samples=best_sample_amount)\nbest_avg = 0\nbest_estimators = -1\nbest_model = None\nfor estimators, model in estimator_models.items():\n    cv_score = evaluate_model(model, x_train, y_train)\n    print(estimators, \" \", cv_score)\n    avg = sum(cv_score)/len(cv_score)\n    if avg > best_avg:\n        best_avg = avg\n        best_estimators = estimators\n        best_model = model\n\nprint(f\"Best model with {best_feature_amount} features, {best_sample_amount} samplesize and {best_estimators} estimators\")\nprint(\"yo\")\"\"\"\nbest_model = RandomForestClassifier(random_state=33, max_features=best_feature_amount, max_samples=best_sample_amount, n_estimators=150)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d028a453",
    "tags": [],
    "execution_start": 1620981774583,
    "execution_millis": 45734,
    "cell_id": "00021-b19bb9ec-62f7-4d67-8e1f-0c27b7caee63",
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# Make final model\n\nfinal_model = best_model.fit(x_train, y_train)\n\nprint(\"Classification accuracy:\")\nclassification_dict = dict()\naccuracy_list = list()\n\nfor key in x_test_dict:\n    x_test = x_test_dict[key].drop([' TimeStamp (s)', 'Pose'], axis=1)\n    classifications = final_model.predict(x_test)\n    annotated_positions = y_test_dict[key].to_numpy()\n    correct_classifications = (classifications == annotated_positions).sum()\n    accuracy_list.append(round(correct_classifications/len(classifications)*100,2))\n    print(f\"{key}: {accuracy_list[-1]}%\")\n    classification_dict[key] = classifications\n\navg = round(sum(accuracy_list)/len(accuracy_list),2)\nprint(f\"Average accuracy: {avg}%\\nWith 150 estimators and\\nrandom_state={33}\")\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Visualization\n",
   "metadata": {
    "tags": [],
    "cell_id": "00022-99b19181-c8b4-432d-a470-c99459aab784",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 51747,
    "execution_start": 1620979952458,
    "output_cleared": true,
    "source_hash": "cc265212",
    "tags": [],
    "cell_id": "00023-b39b7113-325f-49d0-b745-d6d52f674f52",
    "deepnote_cell_type": "code"
   },
   "source": "width=16\nheight=4*len(x_test_dict)\nfig, axes = plt.subplots(len(x_test_dict), 4, figsize=(width, height))\nfor i, key in enumerate(x_test_dict):\n    cols = [f\"{key}: Model classifications\", f\"{key}: Model heatmap\", f\"{key}: Annotated classifications\", f\"{key}: Annotated heatmap\"]\n    df_predict = pd.DataFrame({' Timestamp (s)': x_test_dict[key][' TimeStamp (s)'],'Pose':classification_dict[key]})\n    sns.lineplot(ax=axes[i, 0], data=df_predict,x=' Timestamp (s)',y='Pose')\n    sns.heatmap(ax=axes[i, 1], data=confusion_matrix(y_test_dict[key], classification_dict[key]), cmap=\"YlGnBu\", annot=True, fmt=\"d\")\n    sns.lineplot(ax=axes[i, 2], data=x_test_dict[key], x=\" TimeStamp (s)\", y='Pose')\n    sns.heatmap(ax=axes[i, 3], data=confusion_matrix(y_test_dict[key], y_test_dict[key].to_numpy()), cmap=\"YlGnBu\", annot=True, fmt=\"d\")\n    for ax, col in zip(axes[i], cols): ax.set_title(col)\nfig.tight_layout()\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Classification matrix and report",
   "metadata": {
    "tags": [],
    "cell_id": "00024-cc55596e-38c6-414e-ab4a-3668dc8bd4ca",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 245,
    "execution_start": 1620291629631,
    "output_cleared": true,
    "source_hash": "fae3ec62",
    "tags": [],
    "cell_id": "00025-e4b99eba-f34a-48f8-a552-4cf02160a717",
    "deepnote_cell_type": "code"
   },
   "source": "from joblib import dump, load\n#dump(final_model, f'../models/RFC_model_{AMOUNT_OF_SENSORS}.joblib')\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=59d486bc-e14d-4632-9064-12272fc72d11' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {},
  "orig_nbformat": 3,
  "deepnote_notebook_id": "4345abbd-4409-4248-b902-d757d0617f3a",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}