{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import os\n",
    "import time\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tabulate import tabulate\n",
    "sys.path.insert(1, '../utils')\n",
    "from utils.df_utils import df_wrapper\n",
    "from dataclasses import dataclass\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import to_categorical\n",
    "from utils.declarations import training_files, testing_files, POSE_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMOUNT_OF_SENSORS = 3\n",
    "VALIDATION_TESTSET = \"004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_arr = []\n",
    "for key in training_files:\n",
    "    print(key)\n",
    "    elem = df_wrapper(training_files[key].csv_file)\n",
    "    elem.concat_sensor_data(AMOUNT_OF_SENSORS)\n",
    "    elem.align_poses(training_files[key].annot_file, POSE_MAP)\n",
    "    x_train_arr.append(elem)\n",
    "\n",
    "x_train = pd.concat([x.df.drop([' TimeStamp (s)', 'Pose'],axis=1) for x in x_train_arr])\n",
    "y_train = pd.concat([x.df['Pose'] for x in x_train_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_dict = dict()\n",
    "y_test_dict = dict()\n",
    "for key in testing_files:\n",
    "    elem = df_wrapper(testing_files[key].csv_file)\n",
    "    elem.concat_sensor_data(AMOUNT_OF_SENSORS)\n",
    "    elem.align_poses(testing_files[key].annot_file, POSE_MAP)\n",
    "    y_test = elem.df[\"Pose\"]\n",
    "    y_test.index = [i for i in range(len(y_test))]\n",
    "    x_test_dict[key] = elem.df\n",
    "    y_test_dict[key] = y_test\n",
    "\n",
    "x_test = x_test_dict[VALIDATION_TESTSET].drop([' TimeStamp (s)', 'Pose'], axis=1) \n",
    "y_test = y_test_dict[VALIDATION_TESTSET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numpy arrays\n",
    "x_train_numpy = x_train.values\n",
    "x_test_numpy = x_test.values\n",
    "y_train_numpy = y_train.values\n",
    "y_test_numpy = y_test.values\n",
    "\n",
    "# Hot encode categories into numbers\n",
    "y_train = to_categorical(y_train_numpy,9)\n",
    "y_test = to_categorical(y_test_numpy,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_numpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "NUM_TIMESTAMPS = 100\n",
    "\n",
    "def create_3d_array(array):\n",
    "\n",
    "    arr_3d = []\n",
    "    temp_2d = []\n",
    "    for i in range(1,len(array)):\n",
    "        temp_2d.append(array[i])\n",
    "        if i % NUM_TIMESTAMPS == 0:\n",
    "            arr_3d.append(temp_2d)\n",
    "            temp_2d = []\n",
    "    \n",
    "    return arr_3d\n",
    "\n",
    "def create_2d_y_array(array):\n",
    "    arr_2d_y_train = []\n",
    "    temp_y_train = []\n",
    "    mode_arr = []\n",
    "\n",
    "    for i in range(1,len(array)):\n",
    "        #temp_2d.append(array[0])\n",
    "        temp_y_train.append(array[i])\n",
    "        if i % NUM_TIMESTAMPS == 0:\n",
    "            mode_arr.append(temp_y_train)\n",
    "\n",
    "            temp_y_train = []\n",
    "            #temp_2d = []\n",
    "\n",
    "    y_train_to_be_encoded = []\n",
    "\n",
    "    for i in range(len(mode_arr)):\n",
    "        mode = stats.mode(mode_arr[i])\n",
    "        y_train_to_be_encoded.append(mode.mode[0])\n",
    "\n",
    "    #ONE HOT ENCODING\n",
    "    encoding = []\n",
    "    for value in y_train_to_be_encoded:\n",
    "        vector = [0 for _ in range(9)]\n",
    "        vector[value] = 1\n",
    "        encoding.append(vector)\n",
    "    \n",
    "    return np.array(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(create_3d_array(x_train_numpy, NUM_TIMESTAMPS))\n",
    "y_train = np.array(create_2d_y_array(y_train_numpy, NUM_TIMESTAMPS))\n",
    "\n",
    "x_test = np.array(create_3d_array(x_test_numpy, NUM_TIMESTAMPS))\n",
    "y_test = np.array(create_2d_y_array(y_test_numpy, NUM_TIMESTAMPS))\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "OPTIM = Adam(learning_rate=0.00001)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(1024, activation='sigmoid', input_shape=[x_train.shape[1], x_train.shape[2]]))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(700, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "model.compile(optimizer=OPTIM,  loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=256, epochs=50, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(model.history.history)\n",
    "history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1d = []\n",
    "predictions_1d = []\n",
    "for i in range(len(y_test)):\n",
    "    y_test_1d.append(np.argmax(y_test[i]))\n",
    "    predictions_1d.append(np.argmax(predictions[i]))\n",
    "\n",
    "sns.heatmap(data=confusion_matrix(y_test_1d,predictions_1d), cmap=\"YlGnBu\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}