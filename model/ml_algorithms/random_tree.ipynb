{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "csv_train = pd.read_csv(\"../../data/train_data/Simon_train_3.csv\")\n",
    "df_train = pd.DataFrame(csv_train)\n",
    "\n",
    "df_time_offset = df_train[\"Timestamp\"][0]\n",
    "df_train[\"Timestamp\"] = df_train[\"Timestamp\"] - df_time_offset\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSE_MAP= {\n",
    "    \"rett\": 0,\n",
    "    \"framover\": 1,\n",
    "    \"bakover\": 2,\n",
    "    \"venstre\": 3,\n",
    "    \"hoyre\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp_and_pose(filename):\n",
    "    rows = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        offset = float(lines[1].strip().split(\";\")[1]) # This offset is the duration spent in the video before recording of data begun.\n",
    "        for l in lines[1:]:\n",
    "            sep_row = l.strip().split(\";\")\n",
    "            finished_row = [round(float(x)-offset,2) for x in sep_row[1:3]]\n",
    "            finished_row.append(POSE_MAP[sep_row[3].lower()])\n",
    "            rows.append(finished_row)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = \"../../data/train_data/simon_train_3.txt\"\n",
    "stamped_poses = get_timestamp_and_pose(f_name)\n",
    "print(stamped_poses)\n",
    "\n",
    "df_stamped_poses = []\n",
    "pose_index = 0\n",
    "row_index = 0\n",
    "for stamp in df_train[\"Timestamp\"]:  \n",
    "    pose_id = -1\n",
    "    if stamp <= stamped_poses[-1][1]: \n",
    "        if stamp > stamped_poses[pose_index][1]:\n",
    "            pose_index += 1\n",
    "        pose_id = stamped_poses[pose_index][2]\n",
    "        # If timestamp is in new index, but haven't reached the starting time of this interval yet, set pose_id to default value 5.\n",
    "        if stamp >= stamped_poses[pose_index][0]:\n",
    "            df_stamped_poses.append(pose_id)\n",
    "        else:\n",
    "            df_train = df_train.drop(row_index)\n",
    "    row_index += 1\n",
    "\n",
    "    # If timestamp of the data point exceeds last timestamp recorded by the annotation, append default -1 value\n",
    "    #df_stamped_poses.append(pose_id)\n",
    "\n",
    "#print(df_stamped_poses)\n",
    "\n",
    "df_train[\"Pose\"] = df_stamped_poses\n",
    "#print(df[2400:2500][:])\n",
    "print(len(df_train.index))\n",
    "print(len(df_stamped_poses))\n",
    "y_train = df_train[\"Pose\"]\n",
    "#df['Pose'].hist(bins=4)\n",
    "sns.lineplot(data=df_train, x=\"Timestamp\", y='Pose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train = df_train.drop(['Timestamp'],axis=1)\n",
    "x_train = x_train.drop(['Pose'],axis=1)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(y_train)\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test = pd.read_csv(\"../../data/test_data/Simon_test_1.csv\")\n",
    "df_test = pd.DataFrame(csv_test)\n",
    "df_time_offset = df_test[\"Timestamp\"][0]\n",
    "df_test[\"Timestamp\"] = df_test[\"Timestamp\"] - df_time_offset\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = \"../../data/annotation/Simon_test_1.txt\"\n",
    "stamped_poses = get_timestamp_and_pose(test_name)\n",
    "print(stamped_poses)\n",
    "\n",
    "df_stamped_poses = []\n",
    "pose_index = 0\n",
    "row_index = 0\n",
    "drops = 0\n",
    "for stamp in df_test[\"Timestamp\"]:  \n",
    "    pose_id = -1\n",
    "    if stamp <= stamped_poses[-1][1] and stamp >= stamped_poses[0][0]:\n",
    "        if stamp > stamped_poses[pose_index][1]:\n",
    "            pose_index += 1\n",
    "        pose_id = stamped_poses[pose_index][2]\n",
    "        # If timestamp is in new index, but haven't reached the starting time of this interval yet, set pose_id to default value 5.\n",
    "        if stamp >= stamped_poses[pose_index][0]:\n",
    "            df_stamped_poses.append(pose_id)\n",
    "        else:\n",
    "            df_test = df_test.drop(row_index)\n",
    "    else:\n",
    "        df_test = df_test.drop(row_index)\n",
    "    row_index += 1\n",
    "\n",
    "    # If timestamp of the data point exceeds last timestamp recorded by the annotation, append default -1 value\n",
    "    #df_stamped_poses.append(pose_id)\n",
    "\n",
    "#print(df_stamped_poses)\n",
    "print(len(df_test.index))\n",
    "print(\"drops: {}\".format(drops))\n",
    "print(len(df_stamped_poses))\n",
    "df_test[\"Pose\"] = df_stamped_poses\n",
    "y_test = df_stamped_poses\n",
    "#print(df[2400:2500][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.drop(['Timestamp'],axis=1)\n",
    "x_test = x_test.drop(['Pose'],axis=1)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = 100\n",
    "accuracy_array = []\n",
    "estimators_array = []\n",
    "for num in range(200):\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    rfc.fit(x_train,y_train)\n",
    "    predictions = rfc.predict(x_test)\n",
    "    number_of_corrects = 0\n",
    "   \n",
    "    for num in range(len(predictions)):\n",
    "        if(predictions[num] == y_test[num]):\n",
    "            number_of_corrects += 1\n",
    "\n",
    "    print(\"number of correct: {}\".format(number_of_corrects))\n",
    "    print(\"number of guesses: {}\".format(len(predictions)))\n",
    "    print(\"% correct: {}\".format(number_of_corrects/len(predictions)*100))\n",
    "    accuracy_array.append(number_of_corrects/len(predictions)*100)\n",
    "    estimators_array.append(n_estimators)\n",
    "    print(\"K: {}\".format(n_estimators))\n",
    "    n_estimators+= 1\n",
    "    print(accuracy_array)\n",
    "    print(estimators_array)\n",
    "\n",
    "resframe = pd.DataFrame({'n_estimators':estimators_array, '%':accuracy_array})\n",
    "resframe\n",
    "    \n",
    "\n",
    "#sns.lineplot(data=resframe,x=\"n_estimators\",y=\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resframe = pd.DataFrame({'n_estimators':estimators_array, '%':accuracy_array})\n",
    "print(resframe.max())\n",
    "sns.lineplot(data=resframe,x=\"n_estimators\",y=\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparray = np.array(accuracy_array)\n",
    "np.amax(nparray)\n",
    "index = np.where(nparray == np.amax(nparray))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=163)\n",
    "rfc.fit(x_train,y_train)\n",
    "predictions = rfc.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.DataFrame({'x':df_test['Timestamp'],'y':predictions})\n",
    "sns.lineplot(data=df_predict,x='x',y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions, zero_division=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, predictions), cmap=\"YlGnBu\", annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_corrects = 0\n",
    "for num in range(len(predictions)):\n",
    "    if(predictions[num] == y_test[num]):\n",
    "        number_of_corrects += 1\n",
    "\n",
    "print(\"number of correct: {}\".format(number_of_corrects))\n",
    "print(\"number of guesses: {}\".format(len(predictions)))\n",
    "print(\"% correct: {}\".format(number_of_corrects/len(predictions)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f4fde45515710cbe4f4cf44a8ddef1b298277709bd6c5462499553af68a98f2e"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}